{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mechanicalsoup\n",
    "import bs4, re, lxml, unidecode\n",
    "import base64,glob,os\n",
    "from appscript import *\n",
    "import cellbell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "browser = mechanicalsoup.Browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "download='L1VzZXJzL2dpbGxlcy9Eb3dubG9hZHMv'\n",
    "vrac='L1ZvbHVtZXMvZ2lsbGVzL1RyYW5zZmVydC9WcmFjMi8='\n",
    "linkFilter=[\"c2l0ZXJpcA==\",\"bGVzYmlhbg==\",\"MTlbNzg5XVxk\",\"c2hlbWFsZQ==\",\"dHJhbnM=\",'W3NTXXF1aXJ0']\n",
    "urlBase='aHR0cDovL2Z1bGx4eHhtb3ZpZXMubmV0L3BhZ2UvJWQv'\n",
    "numLettres=\"ABCDEFGHIJKLMNOP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numPage=1\n",
    "nbPages=4\n",
    "extension=\"\"\n",
    "safariLoad=False\n",
    "boolPrint=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def en(s):\n",
    "    return base64.b64encode(s)\n",
    "def de(s):\n",
    "    return base64.b64decode(s)\n",
    "de(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getSoup(url):\n",
    "    page = browser.get(url)\n",
    "    soup = bs4.BeautifulSoup(page.content,\"lxml\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSubLinks(soup,tag=\"article\"):\n",
    "    links=[]\n",
    "    for article in soup.find_all(tag):\n",
    "        href=article.find('a')[\"href\"]\n",
    "        if linkFilter:\n",
    "            lF=[de(l) for l in linkFilter]\n",
    "            match=\"(\"+\"|\".join(lF)+\")\"\n",
    "            m=re.search(match,href)\n",
    "            if not m:\n",
    "                links.append(article.find('a')[\"href\"])\n",
    "        else:\n",
    "            links.append(article.find('a')[\"href\"])\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterASoup(soup,chaine,splitter,link):\n",
    "    for a in soup.find_all('a'):\n",
    "        href=a.get(\"href\")\n",
    "        if href and chaine in href:\n",
    "            link=href.split(splitter)[-1]\n",
    "    return link\n",
    "\n",
    "def getTwitterSecurelyLink(url):\n",
    "    link=url\n",
    "    soup=getSoup(url)\n",
    "    link=filterASoup(soup,\"url=https://openload.co\",\"url=\",link)\n",
    "    if link==url:\n",
    "        link=filterASoup(soup,\"u=https://openload.co\",\"u=\",link)\n",
    "    if link==url:\n",
    "        print \"no share link\"\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSecurelyLink(url):\n",
    "    link=url\n",
    "    for meta in getSoup(url).find_all(\"meta\"):\n",
    "        content=meta.get(\"content\")\n",
    "        if content and \"://openload.co\" in content:\n",
    "            link=content\n",
    "    if link==url:\n",
    "        print \"no content link\",link\n",
    "        link=getTwitterSecurelyLink(url)\n",
    "    elif \"securely.link\" in link:\n",
    "        print \"recursive securely\",link\n",
    "        link=getSecurelyLink(link)\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOpenloadLinks(soup):\n",
    "    links=[]\n",
    "    for article in soup.find_all(\"div\",class_=\"entry-content\"):\n",
    "        aSoup=article.find_all('a')\n",
    "        for a in aSoup:\n",
    "            link=a[\"href\"]\n",
    "            if u\"openload.co\" in link:\n",
    "                links.append(link)\n",
    "            elif u\"openload.co\" in a.text.lower() and u\"securely.link\" in link:\n",
    "                links.append(getSecurelyLink(link))\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNextPage(soup):\n",
    "    try:\n",
    "        nextPage=soup.find(\"a\", class_=\"next page-numbers\")[\"href\"]\n",
    "    #    print nextPage.rsplit(\"/\")[-1]\n",
    "        return getSoup(nextPage)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def pageLoop(urls,safariLoad=True,boolPrint=False,missing=[]):\n",
    "    olURLs={}\n",
    "    for url in urls:\n",
    "        urlSoup=getSoup(url)\n",
    "        for nLink,link in enumerate(getOpenloadLinks(urlSoup)):\n",
    "            if u\"openload.co\" in link:\n",
    "                sLink=link.rsplit(\"/\")[-1]\n",
    "            else:\n",
    "                sLink=link\n",
    "            if not sLink[-4:]==\".mp4\":\n",
    "                sLink+=\".mp4\"\n",
    "            boolMissing=sLink in missing\n",
    "            if (boolPrint or safariLoad) and not boolMissing:\n",
    "                print urlSoup.title.text\n",
    "                print sLink\n",
    "                print link\n",
    "            fileNames[sLink]=urlSoup.title.text+\"-%d\"%nLink\n",
    "            olURLs[sLink]=link\n",
    "            if safariLoad and not boolMissing:\n",
    "                ok=raw_input(\"Press Enter to continue...\")\n",
    "                if ok.lower()!=\"n\":\n",
    "                    safari.windows.first.make(new=k.tab,with_properties={k.URL:link})\n",
    "                else:\n",
    "                    break\n",
    "            elif boolMissing:\n",
    "                safari.windows.first.make(new=k.tab,with_properties={k.URL:link})\n",
    "    return olURLs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# accueil.soup is a BeautifulSoup object http://www.crummy.com/software/BeautifulSoup/bs4/doc/#beautifulsoup \n",
    "# we grab the search form\n",
    "formulaire = accueil.soup.select(\"form\")[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# fill out the search in the right box\n",
    "formulaire.select(\"#ctl00_cphMainContent_m_ctrlSearchEngine_m_ctrlRechercheForm_m_txtSearch\")[0][\"value\"]=\"tarte tatin\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# submit form\n",
    "recherche = browser.submit(formulaire, accueil.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dictinvert(d):\n",
    "    inv = {}\n",
    "    for k, v in d.iteritems():\n",
    "        keys = inv.setdefault(v, [])\n",
    "        keys.append(k)\n",
    "    return inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizeName(name):\n",
    "    result=\"\".join([l.capitalize() for l in name.rsplit(\"-\",1)[0].rsplit(\"(\",1)[0].split(\" \") if l!=\"\"])\n",
    "    result=result.replace(\"-\",\"\").replace(\"!\",\"\").replace(\"'\",\"\").replace(\":\",\"\")\n",
    "    return unidecode.unidecode(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def suffixName(element):\n",
    "    nameKey,suffix=fileNames[element].rsplit(\"-\",1)\n",
    "    suffix=int(suffix)\n",
    "    name=normalizeName(fileNames[element])\n",
    "    if len(nameFiles[nameKey])>1:\n",
    "        name+=numLettres[suffix]    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stripName(name):\n",
    "    return unidecode.unidecode(name.rsplit(\"-\",1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRepFiles(repName=de(download)):\n",
    "    return [l.rsplit(\"/\")[-1] for l in glob.glob(repName+u\"*.mp4\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPages():\n",
    "    olURLs={}\n",
    "    localPage=page\n",
    "    print linkPage.rsplit(\"/\")[-1]\n",
    "    for i in range(nbPages):\n",
    "        print \"page %02d\"%i\n",
    "        urls=getSubLinks(localPage)\n",
    "        olURLs.update(pageLoop(urls,safariLoad=safariLoad,boolPrint=boolPrint,missing=missing))\n",
    "        localPage = getNextPage(localPage)\n",
    "        if not localPage:\n",
    "            break\n",
    "    return olURLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSelectNums(selectNums):\n",
    "    missingNums=[]\n",
    "    for num in selectNums:\n",
    "        key=sorted(nameFiles.keys())[num]\n",
    "        print key\n",
    "        missingNums.extend(nameFiles[key])\n",
    "    print missingNums\n",
    "    missingURLs=[olURLs[name] for name in missingNums]\n",
    "    return missingURLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSelection(selection):\n",
    "    for link in selection:\n",
    "        safari.windows.first.make(new=k.tab,with_properties={k.URL:link})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safari = app(\"Safari\")\n",
    "repName=de(download)\n",
    "fileNames={}\n",
    "#nameFiles={}\n",
    "try:\n",
    "    missing\n",
    "except NameError:\n",
    "    missing = []\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numPage=1\n",
    "nbPages=4\n",
    "extension=u\"\"\n",
    "linkPage=de(urlBase)%numPage\n",
    "page=getSoup(linkPage+extension)\n",
    "urls=getSubLinks(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print getSoup(urls[0]).find(\"title\").text\n",
    "olURLs=getPages()\n",
    "\n",
    "nameFiles=dictinvert({f:stripName(fileNames[f]) for f in fileNames})\n",
    "repFiles=getRepFiles(de(vrac))+getRepFiles()\n",
    "for num,name in enumerate(sorted(nameFiles.keys())):\n",
    "    sub=normalizeName(name)\n",
    "    if filter(lambda x: sub in x, repFiles):\n",
    "        print \"\\t%02d+\"%num,name\n",
    "    else:\n",
    "        print \"%02d \"%num,name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strSelect=raw_input(\"Selected numbers\\n\")\n",
    "if strSelect:\n",
    "    selectNums=strSelect.split()\n",
    "    selectNums=[int(n) for n in selectNums]\n",
    "    print selectNums\n",
    "    missing=getSelectNums(selectNums)\n",
    "print len(missing)\n",
    "strGetPages=raw_input(\"Get pages\\n\")\n",
    "if strGetPages==\"y\":\n",
    "    getSelection(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olURLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getPages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repFiles=getRepFiles()\n",
    "for element in sorted(repFiles):\n",
    "    if element in fileNames:\n",
    "        name=suffixName(element)\n",
    "        print element, name\n",
    "        os.rename(repName+element,repName+name+\".mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def missedDownloads(missing=missing):\n",
    "    missed=set()\n",
    "    targets=set()\n",
    "\n",
    "    for element in glob.glob(de(download)+\"*.mp4*\"):\n",
    "        targets.add(element.split(\".\")[0].split(\"/\")[-1])\n",
    "\n",
    "    for element in missing:\n",
    "        elementMain=element.split(\".\")[0]\n",
    "        if not elementMain in targets:\n",
    "            missed.add(element)\n",
    "    missed=list(missed)\n",
    "    return missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missedDownloads(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def longMissing(missing=missing):\n",
    "    missingLong=set()\n",
    "    for fileName in fileNames:\n",
    "        for element in missing:\n",
    "            if element in fileName:\n",
    "                missingLong.add(fileName)\n",
    "    return list(missingLong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing=missedDownloads(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for element in missing:\n",
    "    print fileNames[element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missingElements=set()\n",
    "for element in missing:\n",
    "    missingElements.add(fileNames[element])\n",
    "print len(missingElements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
