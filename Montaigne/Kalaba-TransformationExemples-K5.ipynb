{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des exemples du K5 pour les papiers déchirés\n",
    "- à partir des exemples de Mahira et de Agathos\n",
    " - sélectionner la première ligne après \\\\gloses\n",
    " - supprimer les espaces entre les mots  \n",
    "- à partie des exemples de Mots\n",
    " - supprimer les environnements preview\n",
    " - supprimer les espaces entre les mots\n",
    " \n",
    "Les fichiers d'entrée sont \"Exemples.tex\" et \"Mots.tex\"\n",
    "Le fichier de sortie est \"Exemples-Texte.tex\"\n",
    "\n",
    "Introduire les deux titres \"La Légende de Agathos\" et \"La Légende de Mahira\" à la main dans Exemples-Texte.tex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation K5\n",
    "Pour la préparation des pièces de puzzle pour le kalaba de Kalabia, il faut mettre compte Phrases-A1-agathos.csv comme fichier Phrases.csv et Phrases-A1-mahira.csv comme fichier Mots.csv dans la chaîne principale du kalaba.\n",
    "\n",
    "Après ça, il y a d'autres étapes spécifiques.\n",
    "1. la coloration des noms propres\n",
    "1. la préparation des exemples pour les papiers déchirés\n",
    "1. la compilation de AA-K5-Texte.tex pour produire le PDF de référence avec les papiers déchirés\n",
    "1. la répartition des papiers entre les 6 fichiers : \n",
    " - AA-K5-Devoir.tex\n",
    " - AA-K5-Devoir-Comp-K1.tex\n",
    " - AA-K5-Devoir-Comp-K2.tex\n",
    " - AA-K5-Devoir-Comp-K3.tex\n",
    " - AA-K5-Devoir-Comp-K4.tex\n",
    " - AA-K5-Devoir-Comp-K5.tex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs, re, string,os\n",
    "from os.path import expanduser\n",
    "import random as rd\n",
    "import pyperclip\n",
    "\n",
    "def ding():\n",
    "    os.system('afplay /System/Library/Sounds/Submarine.aiff')\n",
    "\n",
    "home = expanduser(\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nKalaba=\"K5\"\n",
    "annee=\"23\"\n",
    "RightLeft=True\n",
    "repertoire=home+\"/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/00-ProjetKalaba/%s-%s\"%(annee,nKalaba)\n",
    "serie=repertoire+\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RightLeft\n"
     ]
    }
   ],
   "source": [
    "beginEnv=\"\\\\begin{piece}\\n\\\\tornpaper{%\\n\\\\parbox{.95\\\\textwidth}{\\\\vspace{2ex}\"\n",
    "if \"RightLeft\" in globals() and RightLeft:\n",
    "    print \"RightLeft\"\n",
    "    beginEnv+=\"\\\\raggedleft\"\n",
    "endEnv=\"\\\\vspace{1ex}}\\n}\\n\\\\end{piece}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomExemples=\"Exemples.tex\"\n",
    "with codecs.open(serie+nomExemples,\"r\",encoding=\"utf8\") as input:\n",
    "    lignesExemples=input.readlines()\n",
    "# print len(lignesExemples)\n",
    "\n",
    "nomMots=\"Mots.tex\"\n",
    "with codecs.open(serie+nomMots,\"r\",encoding=\"utf8\") as input:\n",
    "    lignesMots=input.readlines()\n",
    "#print len(lignesMots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best way to split a list into randomly sized chunks?\n",
    "- roippi's answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "from random import gauss\n",
    "\n",
    "def random_chunk(li, moyenne=3.75, var=.5):\n",
    "    it = iter(li)\n",
    "    while True:\n",
    "        nxt = list(islice(it,int(gauss(moyenne,var))))\n",
    "        if nxt:\n",
    "            yield nxt\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list(random_chunk(range(151)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChunks(chunks,point=0,min=4,max=8):\n",
    "    rChunks=[]\n",
    "    nbChunks=rd.randrange(min,max)\n",
    "    lChunk=0\n",
    "    for i in range(0,nbChunks):\n",
    "        rChunks.append(chunks[point+i])\n",
    "        lChunk+=len(chunks[point+i])\n",
    "    print lChunk\n",
    "    return rChunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mahiraExemples=[]\n",
    "for nLigne,ligne in enumerate(lignesExemples):\n",
    "#     print nLigne,ligne\n",
    "    ligne=ligne.strip()\n",
    "    if ligne==\"\\\\gloses\":\n",
    "        mahiraExemples.append(\"{}\".join(re.split(\"{} \",lignesExemples[nLigne+1])).strip())\n",
    "mahiraChunks=list(random_chunk(mahiraExemples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453\n"
     ]
    }
   ],
   "source": [
    "autresExemples=[]\n",
    "lignesMots=[ligne for ligne in lignesMots if not ligne.startswith(\"%\")]\n",
    "print len(lignesMots)\n",
    "for nLigne,ligne in enumerate(lignesMots):\n",
    "    ligne=ligne.strip()\n",
    "    if nLigne%3==0:\n",
    "        ligne=ligne.replace(\"\\\\begin{preview}\",\"\")\n",
    "        ligne=ligne.replace(\"\\\\end{preview}\",\"\")\n",
    "        autresExemples.append(\"{}\".join(re.split(\"{} \",ligne))+\"\\\\\\\\\")\n",
    "autresChunks=list(random_chunk(autresExemples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "minAutresChunks=5\n",
    "maxAutresChunks=9\n",
    "autresChunks1=getChunks(autresChunks,0,minAutresChunks,maxAutresChunks)\n",
    "\n",
    "point2=rd.randrange(maxAutresChunks+2,len(autresChunks)-maxAutresChunks)\n",
    "autresChunks2=getChunks(autresChunks,point2,minAutresChunks,maxAutresChunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3\n",
      "1 3\n",
      "2 3\n",
      "3 3\n",
      "4 4\n",
      "5 3\n",
      "6 4\n",
      "7 3\n",
      "8 3\n",
      "9 3\n",
      "10 3\n",
      "11 4\n",
      "12 4\n",
      "13 3\n",
      "14 3\n",
      "15 3\n",
      "16 2\n",
      "17 3\n",
      "18 3\n",
      "19 3\n",
      "20 3\n",
      "21 3\n",
      "22 4\n",
      "23 3\n",
      "24 3\n",
      "25 4\n",
      "26 3\n",
      "27 4\n",
      "28 3\n",
      "29 3\n",
      "30 3\n",
      "31 4\n",
      "32 3\n",
      "33 3\n",
      "34 3\n",
      "35 3\n",
      "36 3\n",
      "37 3\n",
      "38 4\n",
      "39 3\n",
      "40 3\n",
      "41 3\n",
      "42 3\n",
      "43 4\n",
      "44 3\n",
      "45 4\n",
      "46 3\n",
      "47 3\n",
      "48 3\n",
      "####################\n",
      "47\n",
      "0 3\n",
      "1 3\n",
      "2 3\n",
      "3 4\n",
      "4 3\n",
      "5 3\n",
      "6 3\n",
      "7 3\n",
      "8 3\n",
      "9 3\n",
      "10 4\n",
      "11 3\n",
      "12 3\n",
      "13 3\n",
      "14 3\n",
      "15 3\n",
      "16 4\n",
      "17 4\n",
      "18 4\n",
      "19 3\n",
      "20 3\n",
      "21 3\n",
      "22 3\n",
      "23 4\n",
      "24 3\n",
      "25 3\n",
      "26 2\n",
      "27 4\n",
      "28 4\n",
      "29 3\n",
      "30 4\n",
      "31 4\n",
      "32 3\n",
      "33 3\n",
      "34 3\n",
      "35 4\n",
      "36 3\n",
      "37 3\n",
      "38 3\n",
      "39 3\n",
      "40 3\n",
      "41 3\n",
      "42 3\n",
      "43 3\n",
      "44 4\n",
      "45 3\n",
      "46 2\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "nomExemplesTexte=nomExemples.replace(\".tex\",\"-Texte.tex\")\n",
    "if nomExemplesTexte==nomExemples:\n",
    "    print \"Le nom de la sortie est le même que celui de l'entrée...\"\n",
    "else:\n",
    "    with codecs.open(serie+nomExemplesTexte,\"w\",encoding=\"utf8\") as output:\n",
    "        for nChunk,chunk in enumerate(mahiraChunks):\n",
    "            print nChunk, len(chunk)\n",
    "            output.write(beginEnv+\"\\n\")\n",
    "            for exemple in chunk:\n",
    "                output.write(exemple+\"\\n\")\n",
    "            output.write(endEnv+\"\\n\")\n",
    "\n",
    "        print \"####################\"\n",
    "        output.write(beginEnv+\"\\n\")\n",
    "        output.write(endEnv+\"\\n\")\n",
    "\n",
    "        print len(autresChunks)\n",
    "        for nChunk,chunk in enumerate(autresChunks):\n",
    "            print nChunk, len(chunk)\n",
    "            output.write(beginEnv+\"\\n\")\n",
    "            for exemple in chunk:\n",
    "                output.write(exemple+\"\\n\")\n",
    "            output.write(endEnv+\"\\n\") \n",
    "            \n",
    "        print \"####################\"\n",
    "        output.write(beginEnv+\"\\n\")\n",
    "        output.write(endEnv+\"\\n\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3\n",
      "1 3\n",
      "2 3\n",
      "3 3\n",
      "4 4\n",
      "5 3\n",
      "6 4\n",
      "7 3\n",
      "8 3\n",
      "9 3\n",
      "10 3\n",
      "11 4\n",
      "12 4\n",
      "13 3\n",
      "14 3\n",
      "15 3\n",
      "16 2\n",
      "17 3\n",
      "18 3\n",
      "19 3\n",
      "20 3\n",
      "21 3\n",
      "22 4\n",
      "23 3\n",
      "24 3\n",
      "25 4\n",
      "26 3\n",
      "27 4\n",
      "28 3\n",
      "29 3\n",
      "30 3\n",
      "31 4\n",
      "32 3\n",
      "33 3\n",
      "34 3\n",
      "35 3\n",
      "36 3\n",
      "37 3\n",
      "38 4\n",
      "39 3\n",
      "40 3\n",
      "41 3\n",
      "42 3\n",
      "43 4\n",
      "44 3\n",
      "45 4\n",
      "46 3\n",
      "47 3\n",
      "48 3\n",
      "####################\n",
      "47\n",
      "0 3\n",
      "1 3\n",
      "2 3\n",
      "3 4\n",
      "4 3\n",
      "5 3\n",
      "6 3\n",
      "7 3\n",
      "8 3\n",
      "9 3\n",
      "10 4\n",
      "11 3\n",
      "12 3\n",
      "13 3\n",
      "14 3\n",
      "15 3\n",
      "16 4\n",
      "17 4\n",
      "18 4\n",
      "19 3\n",
      "20 3\n",
      "21 3\n",
      "22 3\n",
      "23 4\n",
      "24 3\n",
      "25 3\n",
      "26 2\n",
      "27 4\n",
      "28 4\n",
      "29 3\n",
      "30 4\n",
      "31 4\n",
      "32 3\n",
      "33 3\n",
      "34 3\n",
      "35 4\n",
      "36 3\n",
      "37 3\n",
      "38 3\n",
      "39 3\n",
      "40 3\n",
      "41 3\n",
      "42 3\n",
      "43 3\n",
      "44 4\n",
      "45 3\n",
      "46 2\n"
     ]
    }
   ],
   "source": [
    "nomSolutionTexte=nomExemples.replace(\".tex\",\"-Solution.tex\")\n",
    "if nomSolutionTexte==nomExemples:\n",
    "    print \"Le nom de la sortie est le même que celui de l'entrée...\"\n",
    "else:\n",
    "    with codecs.open(serie+nomSolutionTexte,\"w\",encoding=\"utf8\") as output:\n",
    "        for nChunk,chunk in enumerate(mahiraChunks):\n",
    "            print nChunk, len(chunk)\n",
    "            output.write(beginEnv+\"\\n\")\n",
    "            for exemple in chunk:\n",
    "                output.write(\"{} \".join(re.split(\"{}\",exemple)).strip()+\"\\n\")\n",
    "                output.write(\"P{} \".join(re.split(\"{}\",exemple)).strip()+\"\\n\")\n",
    "                output.write(\"G{} \".join(re.split(\"{}\",exemple)).strip()+\"\\n\")\n",
    "            output.write(endEnv+\"\\n\")\n",
    "\n",
    "        print \"####################\"\n",
    "        output.write(beginEnv+\"\\n\")\n",
    "        output.write(endEnv+\"\\n\")\n",
    "        \n",
    "        print len(autresChunks)\n",
    "        for nChunk,chunk in enumerate(autresChunks):\n",
    "            print nChunk, len(chunk)\n",
    "            output.write(beginEnv+\"\\n\")\n",
    "            for exemple in chunk:\n",
    "                output.write(\"{} \".join(re.split(\"{}\",exemple)).strip()+\"\\n\")\n",
    "                output.write(\"P{} \".join(re.split(\"{}\",exemple)).strip()+\"\\n\")\n",
    "                output.write(\"G{} \".join(re.split(\"{}\",exemple)).strip()+\"\\n\")\n",
    "            output.write(endEnv+\"\\n\") "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "annee=\"23\"\n",
    "nKalaba=\"K5\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lines=[]\n",
    "nbPages=32\n",
    "iBlanks=[8,15,24]\n",
    "for i in rd.sample(range(32),32):\n",
    "    n=i+1\n",
    "    if n not in iBlanks:\n",
    "        print n\n",
    "        line=ur\"\\includegraphics[page=%d]{%s-%s-Texte.pdf}\\\\\\hdashrule[0.5ex]{\\textwidth}{1pt}{3mm}\\\\\"%(n,annee,nKalaba)\n",
    "        lines.append(line)\n",
    "pyperclip.copy(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7",
   "language": "python",
   "name": "py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
